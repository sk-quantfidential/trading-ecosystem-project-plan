# TSE-0001.12.0 Implementation Plan: trading-system-engine-py

**Epic**: TSE-0001 Foundation Services & Infrastructure
**Milestone**: TSE-0001.12.0 Named Components Foundation
**Component**: trading-system-engine-py + trading-data-adapter-py
**Status**: Planning Complete
**Date**: 2025-10-08

## Overview

Implement multi-instance infrastructure foundation for trading-system-engine-py, replicating the proven pattern from risk-monitor-py and audit-correlator-go. This enables deployment as singleton (trading-system-engine) or multi-instance (trading-system-engine-LH, trading-system-engine-Alpha) with automatic PostgreSQL schema and Redis namespace derivation.

## Success Criteria (BDD Acceptance)

✅ **Primary**: Trading System Engine can be deployed as singleton or multi-instance with automatic schema/namespace derivation via trading-data-adapter-py

**Validation Points**:
1. Service starts successfully with instance configuration
2. Health endpoint returns instance metadata (service, instance, version, environment, timestamp)
3. Logs include instance context in all messages
4. Data adapter receives correct service identity
5. Docker deployment with environment variables works
6. All tests pass (existing + new startup tests)
7. Clean Architecture principles maintained (no domain contamination)

## Pattern Source Analysis

### Proven Pattern from risk-monitor-py

**Key Components**:
1. **Configuration** (infrastructure/config.py):
   - `service_instance_name: str = Field(default="")`
   - `environment: Literal["development", "testing", "production", "docker"]`
   - `@field_validator('log_level', mode='before')` for normalization
   - `model_post_init()` for instance name derivation

2. **Health Endpoint** (presentation layer):
   - Updated response model with instance metadata
   - Returns: service, instance, version, environment, timestamp (ISO 8601)

3. **Logger Binding** (application layer):
   - Instance context binding in main initialization
   - `logger.bind(service_name=..., instance_name=..., environment=...)`

4. **Data Adapter** (infrastructure integration):
   - Pass service identity to adapter config
   - Adapter derives schema and namespace automatically

5. **Docker Configuration**:
   - `SERVICE_INSTANCE_NAME` environment variable
   - Healthcheck with correct endpoint path
   - Network configuration with static IP

6. **Testing**:
   - Startup tests validating instance awareness
   - Logger context binding validation
   - Data adapter configuration validation

### Differences: trading-system-engine vs risk-monitor

**trading-system-engine-py** differences:
- Uses `src/trading_system/` (not `src/trading_system_engine/`)
- Already has `trading-data-adapter-py` integration in main.py
- Has strategy execution layer (risk-monitor does not)
- Has 100/100 tests passing (more comprehensive than risk-monitor's 44)

**Similarities**:
- Dual HTTP/gRPC server architecture
- FastAPI + gRPC concurrent operation
- Pydantic settings with environment validation
- OpenTelemetry instrumentation
- Service discovery integration
- Data adapter pattern with graceful degradation

## Implementation Phases

### Phase 0: trading-data-adapter-py Configuration (CRITICAL)

**Goal**: Add multi-instance support to data adapter

**File**: `trading-data-adapter-py/src/trading_data_adapter/config.py`

**Changes**:
```python
class AdapterConfig(BaseSettings):
    # Service Identity (NEW)
    service_name: str = Field(default="trading-system-engine")
    service_instance_name: str = Field(default="")
    environment: str = Field(default="development")

    # Multi-tenancy (derived from instance name)
    postgres_schema: Optional[str] = Field(default=None)
    redis_namespace: Optional[str] = Field(default=None)

    def model_post_init(self, __context: Any) -> None:
        """Derive instance-specific configuration."""
        if not self.service_instance_name:
            self.service_instance_name = self.service_name
        if not self.postgres_schema:
            self.postgres_schema = self._derive_schema_name()
        if not self.redis_namespace:
            self.redis_namespace = self._derive_redis_namespace()

    def _derive_schema_name(self) -> str:
        """Derive PostgreSQL schema name from instance name.

        Singleton: trading-system-engine → 'trading'
        Multi-instance: trading-system-engine-LH → 'trading_system_engine_lh'
        """
        if self.service_name == self.service_instance_name:
            # Singleton: use first part of service name
            return self.service_name.split('-')[0]
        # Multi-instance: use full instance name with underscores
        return self.service_instance_name.replace('-', '_').lower()

    def _derive_redis_namespace(self) -> str:
        """Derive Redis namespace from instance name.

        Singleton: trading-system-engine → 'trading'
        Multi-instance: trading-system-engine-LH → 'trading_system:LH'
        """
        if self.service_name == self.service_instance_name:
            # Singleton: use first part of service name
            return self.service_name.split('-')[0]
        # Multi-instance: split at last dash, use colon separator
        parts = self.service_instance_name.split('-', 2)  # ['trading', 'system', 'engine-LH']
        if len(parts) >= 3:
            # Extract suffix after 'engine'
            suffix = parts[2].split('-', 1)[-1] if '-' in parts[2] else parts[2]
            return f"{parts[0]}_{parts[1]}:{suffix}"
        return self.service_instance_name.replace('-', '_')
```

**Tests** (NEW: `tests/test_multi_instance_derivation.py`):
- Singleton schema derivation: trading-system-engine → "trading"
- Singleton namespace derivation: trading-system-engine → "trading"
- Multi-instance schema: trading-system-engine-LH → "trading_system_engine_lh"
- Multi-instance namespace: trading-system-engine-LH → "trading_system:LH"
- Explicit override validation
- Instance name auto-derivation
- Complex instance names (trading-system-engine-Alpha-2)

**Expected Test Count**: 17 tests (match risk-data-adapter-py pattern)

---

### Phase 1: trading-system-engine-py Configuration

**Goal**: Add instance awareness to service configuration

**File**: `src/trading_system/infrastructure/config.py`

**Changes**:
```python
class Settings(BaseSettings):
    # Service Identity (NEW)
    service_name: str = "trading-system-engine"
    service_instance_name: str = Field(default="")  # Auto-derived if empty

    # Update environment Literal
    environment: Literal["development", "testing", "production", "docker"] = "development"

    @field_validator('log_level', mode='before')
    @classmethod
    def normalize_log_level(cls, v: Any) -> str:
        """Normalize log level to uppercase for Literal validation."""
        if isinstance(v, str):
            return v.upper()
        return v

    def model_post_init(self, __context: Any) -> None:
        """Derive instance-specific configuration."""
        if not self.service_instance_name:
            self.service_instance_name = self.service_name
```

**No Tests Modified**: Existing tests should pass without changes

---

### Phase 2: Health Endpoint Enhancement

**Goal**: Add instance metadata to health endpoint

**File**: `src/trading_system/presentation/http/routers/health.py`

**Changes**:
```python
class HealthResponse(BaseModel):
    """Health check response model."""
    status: str
    service: str      # NEW
    instance: str     # NEW
    version: str
    environment: str  # NEW
    timestamp: str    # NEW (ISO 8601 UTC)

@router.get("/health", response_model=HealthResponse)
async def health_check() -> HealthResponse:
    """Basic health check endpoint with instance awareness."""
    settings = get_settings()

    return HealthResponse(
        status="healthy",
        service=settings.service_name,
        instance=settings.service_instance_name,
        version=settings.version,
        environment=settings.environment,
        timestamp=datetime.now(timezone.utc).isoformat(),
    )
```

**File**: `src/trading_system/presentation/http/app.py`

**Changes**:
```python
# Add convenience root-level health endpoint (in addition to /api/v1/health)
app.include_router(health.router, tags=["health-root"])
```

**Tests Modified**: Update existing health tests to match new response model

---

### Phase 3: Structured Logging with Instance Context

**Goal**: Bind instance context to logger

**File**: `src/trading_system/main.py`

**Changes** (in `DualProtocolServer.__init__`):
```python
def __init__(self):
    self.settings = get_settings()
    # ... existing initialization ...

    # Bind instance context to logger for all future logs
    global logger
    logger = logger.bind(
        service_name=self.settings.service_name,
        instance_name=self.settings.service_instance_name,
        environment=self.settings.environment,
    )

    logger.info("Trading System Engine service initializing")
```

**No Tests Modified**: Logging is transparent to existing tests

---

### Phase 4: Data Adapter Integration

**Goal**: Pass service identity to data adapter

**File**: `src/trading_system/main.py`

**Changes** (in `setup_data_adapter` method):
```python
async def setup_data_adapter(self) -> None:
    """Setup and connect data adapter."""
    try:
        # Configure adapter with settings from environment
        adapter_config = AdapterConfig(
            service_name=self.settings.service_name,
            service_instance_name=self.settings.service_instance_name,  # NEW
            environment=self.settings.environment,  # NEW
            postgres_url=self.settings.postgres_url,
            redis_url=self.settings.redis_url,
        )

        self.data_adapter = await create_adapter(adapter_config)
        logger.info("Data adapter configured and connected")

    except Exception as e:
        logger.warning("Data adapter setup failed", error=str(e))
        # Continue without data adapter (degraded mode)
```

**No Tests Modified**: Existing integration tests should pass

---

### Phase 5: Docker Build Configuration

**Goal**: Ensure Docker builds correctly with parent context

**File**: `trading-system-engine-py/Dockerfile`

**Review Needed**: Check if paths are correct for parent directory context
- Likely pattern: `COPY trading-system-engine-py/src/ ./`
- Ensure trading-data-adapter-py is copied and installed first
- Verify PYTHONPATH is set correctly or src copied directly to /app

**Expected**: May already be correct (trading-system-engine-py was implemented after risk-monitor-py)

---

### Phase 6: Docker Deployment Configuration

**Goal**: Add instance awareness to docker-compose

**File**: `orchestrator-docker/docker-compose.yml`

**Changes**:
```yaml
trading-system-engine:
  build:
    context: ..
    dockerfile: trading-system-engine-py/Dockerfile
  environment:
    # Service Identity (NEW)
    - SERVICE_NAME=trading-system-engine
    - SERVICE_INSTANCE_NAME=trading-system-engine  # Singleton
    - ENVIRONMENT=docker
    - LOG_LEVEL=INFO  # Uppercase for validation
    - POSTGRES_URL=postgresql+asyncpg://trading_adapter:trading-adapter-db-pass@172.20.0.20:5432/trading_ecosystem
    - REDIS_URL=redis://trading-adapter:trading-pass@172.20.0.10:6379/0
  healthcheck:
    test: ["CMD", "python3", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8082/api/v1/health')"]
    interval: 10s
    timeout: 5s
    retries: 3
    start_period: 10s
```

**File**: `orchestrator-docker/prometheus/prometheus.yml`

**Changes**:
```yaml
- job_name: 'trading-system-engine'
  static_configs:
    - targets: ['172.20.0.XX:8082']  # Update with actual IP
```

---

### Phase 7: Comprehensive Testing

**Goal**: Create startup tests validating instance awareness

**File**: `tests/unit/test_startup.py` (NEW)

**Test Cases** (15 tests minimum):
1. Server initialization (singleton)
2. Server initialization (multi-instance)
3. Settings with instance name
4. Settings without instance name (auto-derivation)
5. Environment configuration
6. Logger binding with instance context
7. Data adapter configuration with instance identity
8. Settings access
9. Multiple server instances
10. Instance name validation
11. Environment validation
12. Logger context validation
13. Data adapter initialization
14. Graceful shutdown
15. Settings caching

**Pattern**: Match risk-monitor-py test structure exactly

---

### Phase 8: Documentation

**Goal**: Create comprehensive PR documentation

**File**: `trading-system-engine-py/docs/prs/feature-TSE-0001.12.0-named-components-foundation.md`

**Sections**:
1. Summary
2. Changes Overview (8 phases)
3. Integration Points
4. Clean Architecture Compliance
5. BDD Acceptance Criteria
6. Testing Summary
7. Deployment Configuration
8. Migration Path
9. Known Issues
10. Files Changed
11. Dependencies
12. Review Checklist
13. Next Steps

**File**: `trading-system-engine-py/TODO.md`

**Update**: Add TSE-0001.12.0 milestone with completion status

---

## TDD Red-Green-Refactor Workflow

### Phase 0: Data Adapter Tests (RED → GREEN → REFACTOR)

**RED Phase**:
1. Create `tests/test_multi_instance_derivation.py`
2. Write 17 failing tests for derivation logic
3. Run tests: `pytest tests/test_multi_instance_derivation.py -v`
4. Verify all tests fail

**GREEN Phase**:
1. Implement `_derive_schema_name()` in AdapterConfig
2. Implement `_derive_redis_namespace()` in AdapterConfig
3. Implement `model_post_init()` hook
4. Run tests: verify all 17 tests pass

**REFACTOR Phase**:
1. Review implementation for clarity
2. Add docstrings with examples
3. Verify tests still pass

### Phase 1-4: Service Configuration (GREEN → REFACTOR)

**GREEN Phase** (implementations should work first time with existing tests):
1. Update Settings in config.py
2. Update health endpoint
3. Update logger binding
4. Update data adapter integration
5. Run existing tests: `pytest tests/ -v`
6. Verify 100/100 tests still pass

**REFACTOR Phase**:
1. Review code for consistency
2. Add inline comments where needed
3. Verify tests still pass

### Phase 7: Startup Tests (RED → GREEN → REFACTOR)

**RED Phase**:
1. Create `tests/unit/test_startup.py`
2. Write 15 failing tests
3. Run tests: verify failures
4. Review failure messages

**GREEN Phase**:
1. Tests should pass immediately (implementation already done in Phases 1-4)
2. Run tests: verify all 15 pass
3. Run full suite: verify 115/115 tests pass (100 + 15)

**REFACTOR Phase**:
1. Review test organization
2. Add helper functions if needed
3. Verify all tests still pass

---

## Git Workflow

### Branch Strategy

**Feature Branches** (per repository):
- `trading-data-adapter-py`: `feature/TSE-0001.12.0-named-components-foundation`
- `trading-system-engine-py`: `feature/TSE-0001.12.0-named-components-foundation`
- `orchestrator-docker`: `feature/TSE-0001.12.0-named-components-foundation` (already exists)
- `project-plan`: `feature/TSE-0001.12.0-named-components-foundation` (already exists)

### Commit Strategy

**trading-data-adapter-py** (1 commit):
```
feat: Implement TSE-0001.12.0 multi-instance configuration for trading-data-adapter-py

Add multi-instance infrastructure support with automatic PostgreSQL schema and
Redis namespace derivation based on service instance names.

[Full commit message with implementation details]
```

**trading-system-engine-py** (1 commit):
```
feat: Implement TSE-0001.12.0 Named Components Foundation for trading-system-engine-py

Implement multi-instance infrastructure foundation enabling deployment as
singleton (trading-system-engine) or multi-instance (trading-system-engine-LH,
trading-system-engine-Alpha) with automatic schema/namespace derivation.

[Full commit message with 8 phases detailed]
```

**orchestrator-docker** (1 commit):
```
feat: Add trading-system-engine deployment with TSE-0001.12.0 instance awareness

Add trading-system-engine service to docker-compose with multi-instance
infrastructure support and Prometheus scraping configuration.

[Full commit message with deployment details]
```

**project-plan** (1 commit):
```
docs: Update TODO-MASTER.md with trading-system-engine-py TSE-0001.12.0 completion

Update milestone TSE-0001.12.0 to reflect completion of trading-system-engine-py
implementation alongside risk-monitor-py and audit-correlator-go.

[Full commit message with milestone updates]
```

---

## Implementation Order

### Step-by-Step Execution

1. **Create Feature Branch** (trading-data-adapter-py):
   ```bash
   cd trading-data-adapter-py
   git checkout -b feature/TSE-0001.12.0-named-components-foundation
   ```

2. **Phase 0: Data Adapter Configuration** (RED-GREEN-REFACTOR):
   - Create test file
   - Write 17 failing tests
   - Implement derivation logic
   - Verify all tests pass
   - Commit

3. **Create Feature Branch** (trading-system-engine-py):
   ```bash
   cd trading-system-engine-py
   git checkout -b feature/TSE-0001.12.0-named-components-foundation
   ```

4. **Phases 1-4: Service Configuration** (GREEN-REFACTOR):
   - Update config.py
   - Update health endpoint
   - Update logger binding
   - Update data adapter integration
   - Verify existing 100 tests still pass

5. **Phase 5: Docker Build** (if needed):
   - Review Dockerfile
   - Update if necessary
   - Test build

6. **Phase 6: Docker Deployment**:
   - Update docker-compose.yml
   - Update prometheus.yml
   - Test deployment

7. **Phase 7: Startup Tests** (RED-GREEN-REFACTOR):
   - Create test_startup.py
   - Write 15 tests
   - Verify all pass
   - Verify 115 total tests pass

8. **Phase 8: Documentation**:
   - Create PR documentation
   - Update TODO.md
   - Update TODO-MASTER.md

9. **Commit All Changes**:
   - Commit trading-data-adapter-py
   - Commit trading-system-engine-py
   - Commit orchestrator-docker
   - Commit project-plan

---

## Expected Outcomes

### Test Results
- **trading-data-adapter-py**: 17/17 multi-instance tests passing
- **trading-system-engine-py**: 115/115 tests passing (100 existing + 15 startup)
- **No regressions**: All existing tests continue to pass

### Files Modified
- **trading-data-adapter-py**: 2 modified, 1 new (3 total)
- **trading-system-engine-py**: 9 modified, 2 new (11 total)
- **orchestrator-docker**: 2 modified (docker-compose.yml, prometheus.yml)
- **project-plan**: 1 modified (TODO-MASTER.md)

### Clean Architecture Compliance
- ✅ Domain layer: No modifications
- ✅ Application layer: Logger binding only
- ✅ Infrastructure layer: Configuration changes isolated
- ✅ Presentation layer: Health endpoint updates only

### Deployment Ready
- ✅ Docker builds successfully
- ✅ Service starts with instance configuration
- ✅ Health endpoint returns instance metadata
- ✅ Logs include instance context
- ✅ Data adapter derives schema and namespace correctly
- ✅ Prometheus scrapes metrics with instance labels

---

## Risk Assessment

### Low Risk Areas
- Configuration changes (proven pattern from risk-monitor-py)
- Health endpoint updates (straightforward Pydantic model changes)
- Logger binding (transparent to existing code)
- Docker deployment (pattern already validated)

### Medium Risk Areas
- Data adapter derivation logic (mitigated by comprehensive tests)
- Dockerfile paths (may already be correct, review needed)

### Mitigation Strategies
- Follow exact pattern from risk-monitor-py (proven to work)
- Run full test suite after each phase
- Test Docker build before committing
- Validate deployment in orchestrator before finalizing

---

## Success Validation

### Checklist
- [ ] All 17 data adapter derivation tests pass
- [ ] All 115 service tests pass (100 existing + 15 startup)
- [ ] Docker build successful
- [ ] Service starts in docker-compose
- [ ] Health endpoint returns correct instance metadata
- [ ] Logs show instance context
- [ ] Prometheus scrapes metrics
- [ ] Clean Architecture compliance verified
- [ ] PR documentation complete
- [ ] TODO.md updated
- [ ] TODO-MASTER.md updated
- [ ] All commits pushed to feature branches

---

## Next Steps After Completion

1. **Review Implementation**:
   - Compare with risk-monitor-py pattern
   - Verify consistency across both Python implementations
   - Validate against Go implementation pattern

2. **Integration Testing**:
   - Deploy full stack with both services
   - Verify multi-instance capability
   - Test Grafana dashboard integration

3. **Remaining Python Services**:
   - Apply pattern to test-coordinator-py
   - Consider pattern for future Python services

4. **Go Services**:
   - Apply pattern to custodian-simulator-go
   - Apply pattern to exchange-simulator-go
   - Apply pattern to market-data-simulator-go

5. **Production Readiness**:
   - Create multi-instance deployment examples
   - Document scaling strategies
   - Update Grafana dashboards for instance-aware monitoring

---

**Plan Prepared**: 2025-10-08
**Estimated Effort**: 4-6 hours (based on risk-monitor-py experience)
**Dependencies**: risk-monitor-py implementation (completed), risk-data-adapter-py pattern (validated)
**Status**: Ready for implementation
