# Epic TSE-0001.12.0: DevOps Support for Named Components

**Status**: Planning → Implementation
**Created**: 2025-10-06
**Updated**: 2025-10-06 (Applied all critical fixes and improvements)
**Priority**: High
**Scope**: All services (pilot: audit-correlator-go)

---

## Executive Summary

Enable named service instances with Grafana monitoring dashboards to support multiple instances of the same service type (e.g., `exchange-OKX`, `exchange-Binance`) while maintaining singleton services (e.g., `audit-correlator`, `test-coordinator`).

### Key Objectives

1. **Named Instance Support**: Enable SERVICE_INSTANCE_NAME environment variable across all services
2. **Multi-tenancy**: Separate PostgreSQL schemas and Redis namespaces per instance
3. **Service Discovery**: Update Redis service registry with instance-aware keys
4. **Grafana Dashboards**: Two views (Docker DevOps + Simulation Entity)
5. **Volume Management**: Docker volumes for all data and log directories
6. **Backward Compatibility**: Existing deployments continue to work unchanged

---

## Architecture Decisions

### 1. Service Naming Strategy

**Environment Variable**: `SERVICE_INSTANCE_NAME`

**Patterns:**
- **Singleton services**: `SERVICE_INSTANCE_NAME=audit-correlator` (matches SERVICE_NAME)
- **Multi-instance services**: `SERVICE_INSTANCE_NAME=exchange-OKX` (unique identifier)

**Examples:**
```bash
# Singleton
SERVICE_NAME=audit-correlator
SERVICE_INSTANCE_NAME=audit-correlator

# Multi-instance exchange
SERVICE_NAME=exchange-simulator
SERVICE_INSTANCE_NAME=exchange-OKX

# Multi-instance custodian
SERVICE_NAME=custodian-simulator
SERVICE_INSTANCE_NAME=custodian-Komainu
```

### 2. PostgreSQL Schema Strategy

**Schema Naming**: Derived from SERVICE_INSTANCE_NAME

**Derivation Rules:**
```go
func deriveSchemaName(serviceName, instanceName string) string {
    if serviceName == instanceName {
        // Singleton: audit-correlator → "audit"
        parts := strings.Split(serviceName, "-")
        return parts[0]
    }
    // Multi-instance: exchange-OKX → "exchange_okx"
    return strings.ReplaceAll(strings.ToLower(instanceName), "-", "_")
}
```

**Examples:**
- `audit-correlator` → `audit` schema
- `test-coordinator` → `test` schema
- `exchange-OKX` → `exchange_okx` schema
- `custodian-Komainu` → `custodian_komainu` schema
- `market-data-Coinmetrics` → `market_data_coinmetrics` schema

**Benefits:**
- Data isolation per instance
- Independent migrations per instance
- Clear ownership boundaries
- Supports backup/restore per instance

### 3. Redis Namespace Strategy

**Namespace Pattern**: `{service-type}:{instance-id}:{key}`

**Derivation Rules:**
```go
func deriveRedisNamespace(serviceName, instanceName string) string {
    if serviceName == instanceName {
        // Singleton: audit-correlator → "audit"
        parts := strings.Split(serviceName, "-")
        return parts[0]
    }
    // Multi-instance: exchange-OKX → "exchange:OKX"
    parts := strings.SplitN(instanceName, "-", 2)
    if len(parts) == 2 {
        return fmt.Sprintf("%s:%s", parts[0], parts[1])
    }
    return instanceName
}
```

**Examples:**
- `audit-correlator` → `audit:*` keys
- `exchange-OKX` → `exchange:OKX:*` keys
- `exchange-Binance` → `exchange:Binance:*` keys
- `custodian-Komainu` → `custodian:Komainu:*` keys

**Service Discovery Keys:**
- Pattern: `services:{service-name}:{instance-id}` (actual implementation, no `:info` suffix)
- Example: `services:audit-correlator:audit-correlator` (singleton)
- Example: `services:exchange-simulator:exchange-OKX` (multi-instance)
- Example: `services:exchange-simulator:exchange-Binance` (multi-instance)

### 4. Docker Volume Strategy

**Volume Pattern**: `/var/trading-ecosystem/{instance-name}/{data|logs}`

**Examples:**
```yaml
volumes:
  # IMPORTANT: Run scripts/init-volumes.sh before first startup
  - ./volumes/audit-correlator/data:/var/lib/audit-correlator/data
  - ./volumes/audit-correlator/logs:/var/log/audit-correlator
  - ./volumes/exchange-OKX/data:/var/lib/exchange-simulator/data
  - ./volumes/exchange-OKX/logs:/var/log/exchange-simulator
```

**Benefits:**
- Persistent data across container restarts
- Easy debugging via log file access
- Independent data per instance
- Backup/restore per instance

### 5. Service Categories

**Singleton Services** (only one instance):
- `audit-correlator` - System-wide event correlation
- `test-coordinator` - Chaos testing orchestration

**Multi-Instance Services** (can have multiple copies):
- `exchange-simulator` - Exchange connectivity simulation
- `custodian-simulator` - Custodian operations simulation
- `market-data-simulator` - Market data generation
- `trading-system-engine` - Trading strategy execution
- `risk-monitor` - Risk monitoring and alerts

---

## Implementation Plan: audit-correlator-go (Pilot)

### Phase 0: audit-data-adapter-go Configuration Foundation (CRITICAL)

**Priority**: 🔴 **MUST COMPLETE FIRST** - Without this, all subsequent phases will fail

**Files to Modify:**
- `audit-data-adapter-go/internal/config/config.go`
- `audit-data-adapter-go/pkg/adapters/factory.go`

**Problem**: The adapter doesn't currently read SERVICE_INSTANCE_NAME or derive schema/namespace.

**Changes:**

1. **Update RepositoryConfig struct** (`config.go:10-34`):
```go
package config

import (
    "fmt"
    "os"
    "strings"
    // ... existing imports
)

type RepositoryConfig struct {
    // Service Identity (NEW)
    ServiceName         string  // e.g., "audit-correlator", "exchange-simulator"
    ServiceInstanceName string  // e.g., "audit-correlator", "exchange-OKX"

    // Database connections
    PostgresURL string
    RedisURL    string
    MongoURL    string

    // Multi-tenancy (NEW - derived from instance name)
    SchemaName     string  // PostgreSQL schema: "audit", "exchange_okx", etc.
    RedisNamespace string  // Redis key prefix: "audit", "exchange:OKX", etc.

    // Connection pooling
    MaxConnections     int
    MaxIdleConnections int
    ConnectionTimeout  time.Duration
    IdleTimeout        time.Duration

    // Retry configuration
    MaxRetries    int
    RetryInterval time.Duration

    // Cache configuration
    DefaultTTL time.Duration

    // Health check configuration
    HealthCheckInterval time.Duration

    // Environment
    Environment string
}
```

2. **Update LoadRepositoryConfig()** (`config.go:37-63`):
```go
func LoadRepositoryConfig() *RepositoryConfig {
    // Read service identity from environment
    serviceName := getEnv("SERVICE_NAME", "audit-correlator")
    instanceName := getEnv("SERVICE_INSTANCE_NAME", serviceName)

    cfg := &RepositoryConfig{
        // Service Identity
        ServiceName:         serviceName,
        ServiceInstanceName: instanceName,

        // Database connections
        PostgresURL: getEnv("POSTGRES_URL", "postgres://user:password@localhost:5432/trading_ecosystem?sslmode=disable"),
        RedisURL:    getEnv("REDIS_URL", "redis://localhost:6379/0"),
        MongoURL:    getEnv("MONGO_URL", "mongodb://localhost:27017/audit_correlator"),

        // Multi-tenancy - automatically derived from instance name
        SchemaName:     deriveSchemaName(serviceName, instanceName),
        RedisNamespace: deriveRedisNamespace(serviceName, instanceName),

        // Connection pooling
        MaxConnections:     getEnvInt("MAX_CONNECTIONS", 25),
        MaxIdleConnections: getEnvInt("MAX_IDLE_CONNECTIONS", 10),
        ConnectionTimeout:  getEnvDuration("CONNECTION_TIMEOUT", 30*time.Second),
        IdleTimeout:        getEnvDuration("IDLE_TIMEOUT", 10*time.Minute),

        // Retry configuration
        MaxRetries:    getEnvInt("MAX_RETRIES", 3),
        RetryInterval: getEnvDuration("RETRY_INTERVAL", 5*time.Second),

        // Cache configuration
        DefaultTTL: getEnvDuration("DEFAULT_TTL", 1*time.Hour),

        // Health check configuration
        HealthCheckInterval: getEnvDuration("HEALTH_CHECK_INTERVAL", 15*time.Second),

        // Environment
        Environment: getEnv("ENVIRONMENT", "development"),
    }

    return cfg
}
```

3. **Add derivation functions** (NEW - add to config.go):
```go
// deriveSchemaName derives PostgreSQL schema name from service instance
func deriveSchemaName(serviceName, instanceName string) string {
    if serviceName == instanceName {
        // Singleton: audit-correlator → "audit"
        parts := strings.Split(serviceName, "-")
        return parts[0]
    }
    // Multi-instance: exchange-OKX → "exchange_okx"
    return strings.ReplaceAll(strings.ToLower(instanceName), "-", "_")
}

// deriveRedisNamespace derives Redis key namespace from service instance
func deriveRedisNamespace(serviceName, instanceName string) string {
    if serviceName == instanceName {
        // Singleton: audit-correlator → "audit"
        parts := strings.Split(serviceName, "-")
        return parts[0]
    }
    // Multi-instance: exchange-OKX → "exchange:OKX"
    parts := strings.SplitN(instanceName, "-", 2)
    if len(parts) == 2 {
        return fmt.Sprintf("%s:%s", parts[0], parts[1])
    }
    return instanceName
}
```

4. **Add configuration logging** (NEW - add to RepositoryConfig):
```go
// LogConfiguration logs the adapter configuration for debugging
func (cfg *RepositoryConfig) LogConfiguration(logger *logrus.Logger) {
    // Mask passwords in URLs
    maskedPostgres := maskPassword(cfg.PostgresURL)
    maskedRedis := maskPassword(cfg.RedisURL)

    logger.WithFields(logrus.Fields{
        "service_name":     cfg.ServiceName,
        "instance_name":    cfg.ServiceInstanceName,
        "schema":          cfg.SchemaName,
        "redis_namespace": cfg.RedisNamespace,
        "postgres_url":    maskedPostgres,
        "redis_url":       maskedRedis,
        "environment":     cfg.Environment,
    }).Info("Data adapter configuration loaded")
}

func maskPassword(url string) string {
    // Simple password masking: user:password@host → user:***@host
    if strings.Contains(url, "@") {
        parts := strings.SplitN(url, "@", 2)
        if strings.Contains(parts[0], ":") {
            userPass := strings.SplitN(parts[0], "://", 2)
            if len(userPass) == 2 {
                credentials := strings.SplitN(userPass[1], ":", 2)
                if len(credentials) == 2 {
                    return fmt.Sprintf("%s://%s:***@%s", userPass[0], credentials[0], parts[1])
                }
            }
        }
    }
    return url
}
```

**Validation**:
```go
// Add unit test to verify derivation
func TestDeriveSchemaName(t *testing.T) {
    tests := []struct {
        serviceName  string
        instanceName string
        expected     string
    }{
        {"audit-correlator", "audit-correlator", "audit"},
        {"exchange-simulator", "exchange-OKX", "exchange_okx"},
        {"custodian-simulator", "custodian-Komainu", "custodian_komainu"},
    }
    for _, tt := range tests {
        result := deriveSchemaName(tt.serviceName, tt.instanceName)
        assert.Equal(t, tt.expected, result)
    }
}
```

**Why This Phase is Critical**: Without these changes, the adapter won't know which PostgreSQL schema to use or how to namespace Redis keys. All database queries will fail.

---

### Phase 1: audit-correlator-go Configuration Layer

**Files to Modify:**
- `audit-correlator-go/internal/config/config.go`
- `audit-correlator-go/cmd/server/main.go`

**Changes:**

1. **Add ServiceInstanceName field** (`config.go:14-42`):
```go
type Config struct {
    // Service Identity
    ServiceName         string  // "audit-correlator" (service type)
    ServiceInstanceName string  // "audit-correlator" (instance identifier)
    ServiceVersion      string

    // Network Configuration
    HTTPPort int
    GRPCPort int

    // External Services
    RedisURL                string
    ConfigurationServiceURL string

    // Service Discovery
    HealthCheckInterval time.Duration

    // Client Configuration
    RequestTimeout time.Duration
    CacheTTL       time.Duration

    // Logging
    LogLevel string

    // Environment
    Environment string

    // DataAdapter - initialized during Load()
    dataAdapter adapters.DataAdapter
}
```

2. **Update Load() function** (`config.go:44-71`):
```go
func Load() *Config {
    return &Config{
        // Service Identity
        ServiceName:         getEnv("SERVICE_NAME", "audit-correlator"),
        ServiceInstanceName: getEnv("SERVICE_INSTANCE_NAME",
                                   getEnv("SERVICE_NAME", "audit-correlator")),
        ServiceVersion:      getEnv("SERVICE_VERSION", "1.0.0"),

        // Network Configuration
        HTTPPort: getEnvAsInt("HTTP_PORT", 8080),
        GRPCPort: getEnvAsInt("GRPC_PORT", 50051),

        // External Services
        RedisURL:                getEnv("REDIS_URL", "redis://localhost:6379"),
        ConfigurationServiceURL: getEnv("CONFIGURATION_SERVICE_URL", "http://localhost:8090"),

        // Service Discovery
        HealthCheckInterval: getEnvAsDuration("HEALTH_CHECK_INTERVAL", 30*time.Second),

        // Client Configuration
        RequestTimeout: getEnvAsDuration("REQUEST_TIMEOUT", 10*time.Second),
        CacheTTL:       getEnvAsDuration("CACHE_TTL", 5*time.Minute),

        // Logging
        LogLevel: getEnv("LOG_LEVEL", "info"),

        // Environment
        Environment: getEnv("ENVIRONMENT", "development"),
    }
}
```

3. **Add structured logging setup** (NEW - add to main.go after config load):
```go
func main() {
    cfg := config.Load()

    logger := logrus.New()
    logger.SetLevel(logrus.InfoLevel)
    logger.SetFormatter(&logrus.JSONFormatter{})

    // Add instance context to all logs
    logger = logger.WithFields(logrus.Fields{
        "service_name":  cfg.ServiceName,
        "instance_name": cfg.ServiceInstanceName,
        "environment":   cfg.Environment,
    })

    logger.Info("Starting audit-correlator service")

    // ... rest of main
}
```

**Rationale**: ServiceInstanceName defaults to ServiceName for backward compatibility.

---

### Phase 2: Service Discovery Integration

**Files to Modify:**
- `audit-correlator-go/internal/infrastructure/service_discovery.go`

**Changes:**

1. **Update service registration ID** (`service_discovery.go:58`):
```go
// OLD:
ID: fmt.Sprintf("%s-%s", cfg.ServiceName, getServiceInstanceID()),

// NEW:
ID: cfg.ServiceInstanceName,  // Use instance name directly as ID
```

2. **Enhanced service metadata** (`service_discovery.go:65-68`):
```go
Metadata: map[string]string{
    "environment":     cfg.Environment,
    "log_level":       cfg.LogLevel,
    "service_type":    cfg.ServiceName,         // NEW: e.g., "audit-correlator"
    "instance_name":   cfg.ServiceInstanceName, // NEW: e.g., "audit-correlator"
},
```

3. **Update service discovery to use actual repository pattern**:

Note: The actual implementation in `audit-data-adapter-go/internal/redis/service_discovery.go` uses:
```go
func (r *ServiceDiscoveryRedisRepository) getServiceKey(serviceName, serviceID string) string {
    return fmt.Sprintf("services:%s:%s", serviceName, serviceID)
}
```

So the service discovery registration will use keys like:
- `services:audit-correlator:audit-correlator` (singleton)
- `services:exchange-simulator:exchange-OKX` (multi-instance)

**Redis Key Examples:**
- `services:audit-correlator:audit-correlator` (singleton)
- `services:exchange-simulator:exchange-OKX` (multi-instance)
- `services:exchange-simulator:exchange-Binance` (multi-instance)

---

### Phase 3: PostgreSQL Schema Support

**Files to Modify:**
- `audit-data-adapter-go/internal/postgres/audit_event_repository.go`
- `audit-data-adapter-go/pkg/adapters/audit_data_adapter.go`

**Changes:**

1. **Update SQL queries to use schema prefix**:
```go
// In audit_event_repository.go

// OLD:
query := "SELECT * FROM audit_events WHERE id = $1"

// NEW:
query := fmt.Sprintf("SELECT * FROM %s.audit_events WHERE id = $1", r.config.SchemaName)

// Apply to all queries:
// - CREATE: INSERT INTO {schema}.audit_events
// - READ: SELECT FROM {schema}.audit_events
// - UPDATE: UPDATE {schema}.audit_events
// - DELETE: DELETE FROM {schema}.audit_events
```

2. **Add schema validation** (NEW - add to audit_data_adapter.go):
```go
// Add method to validate schema exists
func (r *AuditEventRepository) validateSchema(ctx context.Context) error {
    query := `
        SELECT EXISTS (
            SELECT 1 FROM information_schema.schemata
            WHERE schema_name = $1
        )
    `
    var exists bool
    err := r.db.QueryRowContext(ctx, query, r.config.SchemaName).Scan(&exists)
    if err != nil {
        return fmt.Errorf("failed to validate schema: %w", err)
    }

    if !exists {
        return fmt.Errorf("schema %s does not exist - run database migrations first", r.config.SchemaName)
    }

    r.logger.WithField("schema", r.config.SchemaName).Info("PostgreSQL schema validated")
    return nil
}

// Call during adapter connection
func (a *AuditDataAdapter) connectPostgreSQL(ctx context.Context) error {
    // ... existing connection code ...

    // Validate schema exists
    repo := postgres.NewAuditEventRepository(a.postgresDB, a.logger, a.config)
    if err := repo.validateSchema(ctx); err != nil {
        a.logger.WithError(err).Warn("Schema validation failed - service may not function correctly")
        // Don't fail - allow graceful degradation
    }

    return nil
}
```

**Schema Creation**: Handled by orchestrator-docker PostgreSQL init scripts (Phase 6).

---

### Phase 4: Redis Namespace Support

**Files to Modify:**
- `audit-data-adapter-go/internal/redis/cache_repository.go`
- `audit-data-adapter-go/internal/redis/service_discovery_repository.go`

**Changes:**

1. **Update cache operations to use namespace prefix**:
```go
// In cache_repository.go

func (r *CacheRepository) Set(ctx context.Context, key string, value interface{}, ttl time.Duration) error {
    // Add namespace prefix to all keys
    namespacedKey := fmt.Sprintf("%s:%s", r.config.RedisNamespace, key)
    return r.client.Set(ctx, namespacedKey, value, ttl).Err()
}

func (r *CacheRepository) Get(ctx context.Context, key string, dest interface{}) error {
    namespacedKey := fmt.Sprintf("%s:%s", r.config.RedisNamespace, key)
    return r.client.Get(ctx, namespacedKey).Scan(dest)
}

func (r *CacheRepository) Delete(ctx context.Context, key string) error {
    namespacedKey := fmt.Sprintf("%s:%s", r.config.RedisNamespace, key)
    return r.client.Del(ctx, namespacedKey).Err()
}

// Apply to all cache methods: SetMany, GetMany, DeleteMany, etc.
```

2. **Add namespace validation** (NEW):
```go
// Add method to validate Redis namespace
func (r *CacheRepository) validateNamespace(ctx context.Context) error {
    // Test write to namespace
    testKey := fmt.Sprintf("%s:__validation__", r.config.RedisNamespace)
    err := r.client.Set(ctx, testKey, "ok", 10*time.Second).Err()
    if err != nil {
        return fmt.Errorf("failed to validate Redis namespace: %w", err)
    }

    // Clean up test key
    r.client.Del(ctx, testKey)

    r.logger.WithField("namespace", r.config.RedisNamespace).Info("Redis namespace validated")
    return nil
}

// Call during adapter connection
func (a *AuditDataAdapter) connectRedis(ctx context.Context) error {
    // ... existing connection code ...

    // Validate namespace
    if err := a.cache.validateNamespace(ctx); err != nil {
        a.logger.WithError(err).Warn("Namespace validation failed - key conflicts may occur")
        // Don't fail - allow graceful degradation
    }

    return nil
}
```

---

### Phase 5: Docker Deployment

**Files to Modify:**
- `orchestrator-docker/docker-compose.yml`

**Files to Create:**
- `orchestrator-docker/scripts/init-volumes.sh`

**Changes:**

1. **Update docker-compose.yml**:
```yaml
audit-correlator:
  build:
    context: ..
    dockerfile: audit-correlator-go/Dockerfile
  image: audit-correlator:latest
  container_name: trading-ecosystem-audit-correlator
  restart: unless-stopped
  ports:
    - "127.0.0.1:8083:8080"  # HTTP port
    - "127.0.0.1:50053:50051"  # gRPC port
  networks:
    trading-ecosystem:
      ipv4_address: 172.20.0.80
  volumes:
    # IMPORTANT: Run scripts/init-volumes.sh before first startup
    # Data volumes persist across container restarts
    # Log volumes for debugging and audit trail
    - ./volumes/audit-correlator/data:/var/lib/audit-correlator/data
    - ./volumes/audit-correlator/logs:/var/log/audit-correlator
  environment:
    # Service Identity
    - SERVICE_NAME=audit-correlator
    - SERVICE_INSTANCE_NAME=audit-correlator  # NEW: Explicit singleton identifier
    - SERVICE_VERSION=1.0.0
    - ENVIRONMENT=docker

    # Network Configuration
    - HTTP_PORT=8083
    - GRPC_PORT=50053

    # Database Configuration
    - POSTGRES_URL=postgres://audit_adapter:audit-adapter-db-pass@172.20.0.20:5432/trading_ecosystem?sslmode=disable
    - REDIS_URL=redis://audit-adapter:audit-pass@172.20.0.10:6379/0
    - MONGO_URL=mongodb://172.20.0.20:27017/audit_correlator

    # Configuration
    - MAX_CONNECTIONS=25
    - MAX_IDLE_CONNECTIONS=10
    - CONNECTION_TIMEOUT=30s
    - IDLE_TIMEOUT=10m
    - MAX_RETRIES=3
    - RETRY_INTERVAL=5s
    - DEFAULT_TTL=1h
    - HEALTH_CHECK_INTERVAL=15s

    # Logging
    - LOG_LEVEL=info
  depends_on:
    redis:
      condition: service_healthy
    postgres:
      condition: service_healthy
    service-registry:
      condition: service_healthy
  healthcheck:
    test: ["CMD", "sh", "-c", "wget --quiet --tries=1 -O /dev/null http://localhost:8083/api/v1/health"]
    interval: 15s
    timeout: 5s
    retries: 3
    start_period: 45s
```

2. **Create volume initialization script** (`scripts/init-volumes.sh`):
```bash
#!/bin/bash
# orchestrator-docker/scripts/init-volumes.sh

set -e

echo "Initializing Docker volumes for Trading Ecosystem services..."
echo ""

SERVICES=(
    "audit-correlator"
    "test-coordinator"
    "exchange-OKX"
    "custodian-Komainu"
    "market-data-Coinmetrics"
    "trading-system-LH"
    "risk-monitor-LH"
)

for service in "${SERVICES[@]}"; do
    echo "Creating volumes for ${service}..."
    mkdir -p "./volumes/${service}/data"
    mkdir -p "./volumes/${service}/logs"

    # Set permissions (777 for development, more restrictive in production)
    chmod 777 "./volumes/${service}/data"
    chmod 777 "./volumes/${service}/logs"

    echo "✅ ${service} volumes ready"
done

echo ""
echo "All volumes initialized successfully!"
echo ""
echo "Next steps:"
echo "1. Review volume permissions in ./volumes/"
echo "2. Run 'docker-compose up -d' to start services"
echo "3. Verify logs appear in ./volumes/{service}/logs/"
```

Make script executable:
```bash
chmod +x orchestrator-docker/scripts/init-volumes.sh
```

---

### Phase 6: PostgreSQL Schema Initialization

**Files to Create:**
- `orchestrator-docker/postgres/init/02-audit-correlator-schema.sql`

**Content:**
```sql
-- ============================================================================
-- Audit Correlator Schema Initialization
-- Purpose: Create audit schema for audit-correlator singleton instance
-- ============================================================================

-- Create audit schema
CREATE SCHEMA IF NOT EXISTS audit;

-- Grant permissions to audit_adapter user
GRANT USAGE ON SCHEMA audit TO audit_adapter;
GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA audit TO audit_adapter;
GRANT ALL PRIVILEGES ON ALL SEQUENCES IN SCHEMA audit TO audit_adapter;

-- Set default privileges for future tables
ALTER DEFAULT PRIVILEGES IN SCHEMA audit GRANT ALL ON TABLES TO audit_adapter;
ALTER DEFAULT PRIVILEGES IN SCHEMA audit GRANT ALL ON SEQUENCES TO audit_adapter;

-- ============================================================================
-- Migration Logic: Handle existing audit_events table
-- ============================================================================

DO $$
BEGIN
    -- Check if audit_events exists in public schema
    IF EXISTS (
        SELECT 1 FROM information_schema.tables
        WHERE table_schema = 'public'
        AND table_name = 'audit_events'
    ) THEN
        RAISE NOTICE 'Found audit_events in public schema - migrating to audit schema';

        -- Move table to audit schema
        ALTER TABLE public.audit_events SET SCHEMA audit;

        -- Move sequence if exists
        IF EXISTS (
            SELECT 1 FROM information_schema.sequences
            WHERE sequence_schema = 'public'
            AND sequence_name = 'audit_events_id_seq'
        ) THEN
            ALTER SEQUENCE public.audit_events_id_seq SET SCHEMA audit;
            RAISE NOTICE 'Migrated audit_events_id_seq to audit schema';
        END IF;

        -- Move indexes to audit schema (PostgreSQL moves them automatically with table)
        RAISE NOTICE 'Successfully migrated audit_events from public to audit schema';

    ELSE
        -- Create new table in audit schema
        RAISE NOTICE 'Creating new audit_events table in audit schema';

        CREATE TABLE audit.audit_events (
            id SERIAL PRIMARY KEY,
            event_id VARCHAR(255) UNIQUE NOT NULL,
            service_name VARCHAR(100) NOT NULL,
            event_type VARCHAR(100) NOT NULL,
            trace_id VARCHAR(255),
            correlation_id VARCHAR(255),
            user_id VARCHAR(255),
            metadata JSONB,
            timestamp TIMESTAMP NOT NULL DEFAULT NOW(),
            created_at TIMESTAMP NOT NULL DEFAULT NOW()
        );

        -- Create indexes for common queries
        CREATE INDEX idx_audit_events_trace_id ON audit.audit_events(trace_id);
        CREATE INDEX idx_audit_events_service_name ON audit.audit_events(service_name);
        CREATE INDEX idx_audit_events_event_type ON audit.audit_events(event_type);
        CREATE INDEX idx_audit_events_timestamp ON audit.audit_events(timestamp);
        CREATE INDEX idx_audit_events_correlation_id ON audit.audit_events(correlation_id);

        RAISE NOTICE 'Created new audit_events table with indexes';
    END IF;
END $$;

-- ============================================================================
-- Health Check Function
-- ============================================================================

CREATE OR REPLACE FUNCTION audit.health_check()
RETURNS json AS $$
DECLARE
    table_count INTEGER;
    event_count INTEGER;
BEGIN
    -- Count tables in audit schema
    SELECT COUNT(*) INTO table_count
    FROM information_schema.tables
    WHERE table_schema = 'audit';

    -- Count audit events
    SELECT COUNT(*) INTO event_count
    FROM audit.audit_events;

    RETURN json_build_object(
        'schema', 'audit',
        'status', 'healthy',
        'instance', 'audit-correlator',
        'tables', table_count,
        'events', event_count,
        'timestamp', NOW()
    );
END;
$$ LANGUAGE plpgsql;

-- Grant execute permission to audit_adapter
GRANT EXECUTE ON FUNCTION audit.health_check() TO audit_adapter;

-- ============================================================================
-- Verification
-- ============================================================================

-- Log completion
DO $$
BEGIN
    RAISE NOTICE '✅ Audit schema initialization complete';
    RAISE NOTICE 'Schema: audit';
    RAISE NOTICE 'User: audit_adapter';
    RAISE NOTICE 'Test with: SELECT * FROM audit.health_check();';
END $$;
```

---

### Phase 7: Health Check Enhancement

**Files to Modify:**
- `audit-correlator-go/internal/handlers/health.go`
- `audit-correlator-go/cmd/server/main.go`

**Changes:**

1. **Update HealthHandler struct** (`health.go`):
```go
type HealthHandler struct {
    config       *config.Config          // NEW: Add config field
    auditService *services.AuditService
    logger       *logrus.Logger
}

// NEW: Updated constructor
func NewHealthHandlerWithConfig(cfg *config.Config, auditService *services.AuditService, logger *logrus.Logger) *HealthHandler {
    return &HealthHandler{
        config:       cfg,
        auditService: auditService,
        logger:       logger,
    }
}
```

2. **Update Health endpoint** (`health.go`):
```go
func (h *HealthHandler) Health(c *gin.Context) {
    response := gin.H{
        "status":      "healthy",
        "service":     h.config.ServiceName,         // "audit-correlator"
        "instance":    h.config.ServiceInstanceName, // NEW: "audit-correlator"
        "version":     h.config.ServiceVersion,
        "timestamp":   time.Now().UTC(),
        "environment": h.config.Environment,
    }

    c.JSON(http.StatusOK, response)
}
```

3. **Update main.go to pass config** (`main.go:112`):
```go
// OLD:
healthHandler := handlers.NewHealthHandlerWithAuditService(auditService, logger)

// NEW:
healthHandler := handlers.NewHealthHandlerWithConfig(cfg, auditService, logger)
```

**Health Check Response Example:**
```json
{
  "status": "healthy",
  "service": "audit-correlator",
  "instance": "audit-correlator",
  "version": "1.0.0",
  "timestamp": "2025-10-06T12:00:00Z",
  "environment": "docker"
}
```

---

### Phase 8: Grafana Dashboards

**Files to Create:**
1. `orchestrator-docker/grafana/dashboards/devops-docker-view.json`
2. `orchestrator-docker/grafana/dashboards/simulation-entity-view.json`
3. `orchestrator-docker/grafana/provisioning/dashboards/dashboards.yml`

**Dashboard 1: DevOps Docker View**

**File**: `orchestrator-docker/grafana/dashboards/devops-docker-view.json`

```json
{
  "dashboard": {
    "title": "Trading Ecosystem - DevOps Docker View",
    "tags": ["trading-ecosystem", "devops", "docker"],
    "timezone": "browser",
    "schemaVersion": 16,
    "version": 1,
    "refresh": "10s",
    "panels": [
      {
        "id": 1,
        "title": "Infrastructure Services Health",
        "type": "stat",
        "gridPos": {"x": 0, "y": 0, "w": 24, "h": 4},
        "targets": [
          {
            "expr": "up{job=~\"redis|postgres|prometheus|grafana|jaeger\"}",
            "legendFormat": "{{job}}",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "thresholds": {
              "mode": "absolute",
              "steps": [
                {"value": null, "color": "red"},
                {"value": 0.5, "color": "yellow"},
                {"value": 1, "color": "green"}
              ]
            },
            "mappings": [
              {"type": "value", "value": "0", "text": "DOWN"},
              {"type": "value", "value": "1", "text": "UP"}
            ]
          }
        }
      },
      {
        "id": 2,
        "title": "audit-correlator Health",
        "type": "stat",
        "gridPos": {"x": 0, "y": 4, "w": 6, "h": 3},
        "targets": [
          {
            "expr": "up{job=\"audit-correlator\",instance=\"audit-correlator\"}",
            "legendFormat": "{{instance}}",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "thresholds": {
              "mode": "absolute",
              "steps": [
                {"value": null, "color": "red"},
                {"value": 1, "color": "green"}
              ]
            }
          }
        }
      },
      {
        "id": 3,
        "title": "All Service Instances",
        "type": "table",
        "gridPos": {"x": 0, "y": 7, "w": 24, "h": 8},
        "targets": [
          {
            "expr": "up{job=~\".*-simulator|.*-correlator|.*-coordinator|trading-system.*|risk-monitor.*\"}",
            "format": "table",
            "instant": true,
            "refId": "A"
          }
        ],
        "transformations": [
          {
            "id": "organize",
            "options": {
              "excludeByName": {
                "Time": true,
                "__name__": true
              },
              "indexByName": {
                "instance": 0,
                "job": 1,
                "Value": 2
              },
              "renameByName": {
                "instance": "Instance Name",
                "job": "Service Type",
                "Value": "Health Status"
              }
            }
          }
        ],
        "options": {
          "showHeader": true,
          "sortBy": [{"field": "Instance Name", "desc": false}]
        }
      },
      {
        "id": 4,
        "title": "Container Resource Usage",
        "type": "graph",
        "gridPos": {"x": 0, "y": 15, "w": 12, "h": 8},
        "targets": [
          {
            "expr": "container_memory_usage_bytes{name=~\"trading-ecosystem-.*\"}",
            "legendFormat": "{{name}} - Memory",
            "refId": "A"
          },
          {
            "expr": "rate(container_cpu_usage_seconds_total{name=~\"trading-ecosystem-.*\"}[5m])",
            "legendFormat": "{{name}} - CPU",
            "refId": "B"
          }
        ]
      },
      {
        "id": 5,
        "title": "Service Discovery Registry Count",
        "type": "stat",
        "gridPos": {"x": 12, "y": 15, "w": 12, "h": 8},
        "targets": [
          {
            "expr": "count(up{job=~\".*-simulator|.*-correlator|.*-coordinator\"})",
            "legendFormat": "Registered Services",
            "refId": "A"
          }
        ]
      }
    ]
  }
}
```

**Dashboard 2: Simulation Entity View**

**File**: `orchestrator-docker/grafana/dashboards/simulation-entity-view.json`

```json
{
  "dashboard": {
    "title": "Trading Ecosystem - Simulation Entity View",
    "tags": ["trading-ecosystem", "simulation", "entities"],
    "timezone": "browser",
    "schemaVersion": 16,
    "version": 1,
    "refresh": "5s",
    "panels": [
      {
        "id": 1,
        "title": "Central Services",
        "type": "row",
        "gridPos": {"x": 0, "y": 0, "w": 24, "h": 1}
      },
      {
        "id": 2,
        "title": "audit-correlator (Singleton)",
        "type": "stat",
        "gridPos": {"x": 0, "y": 1, "w": 12, "h": 4},
        "targets": [
          {
            "expr": "up{instance=\"audit-correlator\"}",
            "legendFormat": "Health",
            "refId": "A"
          },
          {
            "expr": "audit_events_total{instance=\"audit-correlator\"}",
            "legendFormat": "Total Events",
            "refId": "B"
          }
        ]
      },
      {
        "id": 3,
        "title": "test-coordinator (Singleton)",
        "type": "stat",
        "gridPos": {"x": 12, "y": 1, "w": 12, "h": 4},
        "targets": [
          {
            "expr": "up{instance=\"test-coordinator\"}",
            "legendFormat": "Health",
            "refId": "A"
          }
        ]
      },
      {
        "id": 4,
        "title": "Trading System Entities",
        "type": "row",
        "gridPos": {"x": 0, "y": 5, "w": 24, "h": 1}
      },
      {
        "id": 5,
        "title": "trading-system-LH Orders",
        "type": "graph",
        "gridPos": {"x": 0, "y": 6, "w": 12, "h": 6},
        "targets": [
          {
            "expr": "rate(orders_total{instance=\"trading-system-LH\"}[5m])",
            "legendFormat": "Orders/sec",
            "refId": "A"
          }
        ]
      },
      {
        "id": 6,
        "title": "risk-monitor-LH Alerts",
        "type": "graph",
        "gridPos": {"x": 12, "y": 6, "w": 12, "h": 6},
        "targets": [
          {
            "expr": "rate(alerts_total{instance=\"risk-monitor-LH\"}[5m])",
            "legendFormat": "Alerts/sec",
            "refId": "A"
          }
        ]
      },
      {
        "id": 7,
        "title": "Exchange Entities",
        "type": "row",
        "gridPos": {"x": 0, "y": 12, "w": 24, "h": 1}
      },
      {
        "id": 8,
        "title": "exchange-OKX Trades",
        "type": "stat",
        "gridPos": {"x": 0, "y": 13, "w": 8, "h": 4},
        "targets": [
          {
            "expr": "trades_total{instance=\"exchange-OKX\"}",
            "legendFormat": "Total Trades",
            "refId": "A"
          }
        ]
      },
      {
        "id": 9,
        "title": "Custodian Entities",
        "type": "row",
        "gridPos": {"x": 0, "y": 17, "w": 24, "h": 1}
      },
      {
        "id": 10,
        "title": "custodian-Komainu Settlements",
        "type": "stat",
        "gridPos": {"x": 0, "y": 18, "w": 8, "h": 4},
        "targets": [
          {
            "expr": "settlements_total{instance=\"custodian-Komainu\"}",
            "legendFormat": "Total Settlements",
            "refId": "A"
          }
        ]
      },
      {
        "id": 11,
        "title": "Market Data Entities",
        "type": "row",
        "gridPos": {"x": 0, "y": 22, "w": 24, "h": 1}
      },
      {
        "id": 12,
        "title": "market-data-Coinmetrics Price Updates",
        "type": "graph",
        "gridPos": {"x": 0, "y": 23, "w": 24, "h": 6},
        "targets": [
          {
            "expr": "rate(price_updates_total{instance=\"market-data-Coinmetrics\"}[5m])",
            "legendFormat": "{{symbol}}",
            "refId": "A"
          }
        ]
      },
      {
        "id": 13,
        "title": "Entity Communication Flow",
        "type": "graph",
        "gridPos": {"x": 0, "y": 29, "w": 24, "h": 8},
        "targets": [
          {
            "expr": "rate(http_requests_total{service=~\"exchange.*|custodian.*|trading-system.*\"}[5m])",
            "legendFormat": "{{service}} -> {{target_service}}",
            "refId": "A"
          }
        ],
        "options": {
          "legend": {
            "displayMode": "table",
            "placement": "bottom"
          }
        }
      }
    ]
  }
}
```

**Dashboard Provisioning**

**File**: `orchestrator-docker/grafana/provisioning/dashboards/dashboards.yml`

```yaml
apiVersion: 1

providers:
  - name: 'trading-ecosystem'
    orgId: 1
    folder: 'Trading Ecosystem'
    type: file
    disableDeletion: false
    editable: true
    updateIntervalSeconds: 10
    allowUiUpdates: true
    options:
      path: /etc/grafana/provisioning/dashboards
      foldersFromFilesStructure: false
```

---

### Phase 9: Python Service Implementation Pattern

**Purpose**: Provide implementation guide for Python services (trading-system-engine-py, risk-monitor-py, test-coordinator-py)

**Pattern for All Python Services:**

#### 1. Service Configuration

**File**: `{service}/src/{service}/infrastructure/config.py`

```python
import os
from typing import Optional
from pydantic import Field
from pydantic_settings import BaseSettings


class Settings(BaseSettings):
    """Service configuration with instance support."""

    # Service Identity
    service_name: str = Field(default="trading-system-engine")
    service_instance_name: str = Field(
        default_factory=lambda: os.getenv(
            "SERVICE_INSTANCE_NAME",
            os.getenv("SERVICE_NAME", "trading-system-engine")
        )
    )
    service_version: str = "1.0.0"

    # Network Configuration
    host: str = "0.0.0.0"
    http_port: int = 8080
    grpc_port: int = 50051

    # Multi-tenancy (derived properties)
    @property
    def schema_name(self) -> str:
        """Derive PostgreSQL schema from instance name.

        Examples:
            trading-system-engine -> trading_system
            trading-system-LH -> trading_system_lh
        """
        if self.service_name == self.service_instance_name:
            # Singleton: trading-system-engine → trading_system
            return self.service_name.replace("-", "_")
        # Multi-instance: trading-system-LH → trading_system_lh
        return self.service_instance_name.replace("-", "_").lower()

    @property
    def redis_namespace(self) -> str:
        """Derive Redis namespace from instance name.

        Examples:
            trading-system-engine -> trading_system
            trading-system-LH -> trading_system:LH
        """
        if self.service_name == self.service_instance_name:
            # Singleton: trading-system-engine → trading_system
            return self.service_name.split("-")[0]
        # Multi-instance: trading-system-LH → trading_system:LH
        parts = self.service_instance_name.split("-", 1)
        return f"{parts[0]}:{parts[1]}" if len(parts) == 2 else self.service_instance_name

    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"


# Singleton instance
_settings: Optional[Settings] = None


def get_settings() -> Settings:
    """Get cached settings instance."""
    global _settings
    if _settings is None:
        _settings = Settings()
    return _settings
```

#### 2. Data Adapter Configuration

**File**: `{service}-data-adapter-py/src/{service}_data_adapter/config.py`

```python
import os
from typing import Optional
from pydantic import Field
from pydantic_settings import BaseSettings


class AdapterConfig(BaseSettings):
    """Data adapter configuration with multi-tenancy support."""

    # Service Identity
    service_name: str = Field(default="trading-system-engine")
    service_instance_name: str = Field(
        default_factory=lambda: os.getenv(
            "SERVICE_INSTANCE_NAME",
            os.getenv("SERVICE_NAME", "trading-system-engine")
        )
    )
    service_version: str = "1.0.0"

    # Database URLs
    postgres_url: str = Field(
        default="postgresql+asyncpg://user:pass@localhost:5432/trading_ecosystem"
    )
    redis_url: str = Field(default="redis://localhost:6379/0")

    # Multi-tenancy (computed fields)
    schema_name: str = Field(default="")
    redis_namespace: str = Field(default="")

    # Connection Pooling
    postgres_pool_size: int = 25
    postgres_max_overflow: int = 10
    redis_pool_size: int = 25

    # Cache TTL
    cache_ttl_default: int = 300  # 5 minutes
    cache_ttl_scenarios: int = 600  # 10 minutes

    # Environment
    environment: str = "development"

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        # Derive schema and namespace if not explicitly set
        if not self.schema_name:
            self.schema_name = self._derive_schema_name()
        if not self.redis_namespace:
            self.redis_namespace = self._derive_redis_namespace()

    def _derive_schema_name(self) -> str:
        """Derive PostgreSQL schema name."""
        if self.service_name == self.service_instance_name:
            # Singleton
            return self.service_name.replace("-", "_")
        # Multi-instance
        return self.service_instance_name.replace("-", "_").lower()

    def _derive_redis_namespace(self) -> str:
        """Derive Redis namespace."""
        if self.service_name == self.service_instance_name:
            # Singleton
            return self.service_name.split("-")[0]
        # Multi-instance
        parts = self.service_instance_name.split("-", 1)
        return f"{parts[0]}:{parts[1]}" if len(parts) == 2 else self.service_instance_name

    class Config:
        # Customize env_prefix per service:
        # - trading-system-engine: "TRADING_SYSTEM_ADAPTER_"
        # - risk-monitor: "RISK_MONITOR_ADAPTER_"
        # - test-coordinator: "TEST_COORDINATOR_ADAPTER_"
        env_prefix = "TRADING_SYSTEM_ADAPTER_"  # Example for trading-system-engine
```

#### 3. Service Lifespan Integration

**File**: `{service}/src/{service}/main.py`

```python
import structlog
from contextlib import asynccontextmanager
from fastapi import FastAPI
from {service}_data_adapter import AdapterFactory, AdapterConfig


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifespan with data adapter integration."""
    settings = get_settings()
    logger = structlog.get_logger()

    # Configure structured logging with instance context
    structlog.configure(
        processors=[
            structlog.contextvars.merge_contextvars,
            structlog.processors.add_log_level,
            structlog.processors.TimeStamper(fmt="iso"),
            structlog.processors.JSONRenderer(),
        ],
        context_class=dict,
        logger_factory=structlog.PrintLoggerFactory(),
    )

    # Add instance context to all logs
    structlog.contextvars.bind_contextvars(
        service_name=settings.service_name,
        instance_name=settings.service_instance_name,
        environment=settings.environment,
    )

    logger.info("Starting service",
                service=settings.service_name,
                instance=settings.service_instance_name,
                schema=settings.schema_name,
                redis_namespace=settings.redis_namespace)

    # Initialize data adapter
    adapter_config = AdapterConfig(
        service_name=settings.service_name,
        service_instance_name=settings.service_instance_name,
        postgres_url=settings.postgres_url,
        redis_url=settings.redis_url,
    )

    adapter_factory = AdapterFactory(adapter_config)
    app.state.adapter_factory = adapter_factory

    try:
        await adapter_factory.initialize()
        health = await adapter_factory.health_check()
        logger.info("Data adapter initialized",
                    postgres_connected=health["postgres"]["connected"],
                    redis_connected=health["redis"]["connected"],
                    schema=adapter_config.schema_name,
                    namespace=adapter_config.redis_namespace)
    except Exception as e:
        logger.warning("Data adapter initialization failed, using stub repositories",
                       error=str(e))

    yield

    # Cleanup
    try:
        await adapter_factory.cleanup()
        logger.info("Data adapter cleaned up successfully")
    except Exception as e:
        logger.error("Data adapter cleanup failed", error=str(e))
```

#### 4. Health Endpoint

**File**: `{service}/src/{service}/presentation/health.py`

```python
from fastapi import APIRouter, Request
from {service}.infrastructure.config import get_settings


router = APIRouter()


@router.get("/health")
async def health(request: Request):
    """Health check endpoint with instance information."""
    settings = get_settings()

    return {
        "status": "healthy",
        "service": settings.service_name,
        "instance": settings.service_instance_name,  # NEW
        "version": settings.service_version,
        "environment": settings.environment,
        "schema": settings.schema_name,              # NEW
        "namespace": settings.redis_namespace,       # NEW
    }
```

---

## Testing Strategy

### Unit Tests

**Test Coverage:**
1. Config parsing with SERVICE_INSTANCE_NAME
2. Schema name derivation for singleton and multi-instance
3. Redis namespace derivation
4. Service registration ID generation
5. Health check response includes instance name
6. Password masking in configuration logging

**Example Test (Go)**:
```go
func TestDeriveSchemaName(t *testing.T) {
    tests := []struct {
        serviceName  string
        instanceName string
        expected     string
    }{
        {"audit-correlator", "audit-correlator", "audit"},
        {"exchange-simulator", "exchange-OKX", "exchange_okx"},
        {"custodian-simulator", "custodian-Komainu", "custodian_komainu"},
        {"market-data-simulator", "market-data-Coinmetrics", "market_data_coinmetrics"},
    }

    for _, tt := range tests {
        t.Run(tt.instanceName, func(t *testing.T) {
            result := deriveSchemaName(tt.serviceName, tt.instanceName)
            assert.Equal(t, tt.expected, result)
        })
    }
}

func TestDeriveRedisNamespace(t *testing.T) {
    tests := []struct {
        serviceName  string
        instanceName string
        expected     string
    }{
        {"audit-correlator", "audit-correlator", "audit"},
        {"exchange-simulator", "exchange-OKX", "exchange:OKX"},
        {"custodian-simulator", "custodian-Komainu", "custodian:Komainu"},
    }

    for _, tt := range tests {
        t.Run(tt.instanceName, func(t *testing.T) {
            result := deriveRedisNamespace(tt.serviceName, tt.instanceName)
            assert.Equal(t, tt.expected, result)
        })
    }
}
```

**Example Test (Python)**:
```python
def test_schema_name_derivation():
    """Test PostgreSQL schema name derivation."""
    # Singleton
    config = AdapterConfig(
        service_name="trading-system-engine",
        service_instance_name="trading-system-engine"
    )
    assert config.schema_name == "trading_system_engine"

    # Multi-instance
    config = AdapterConfig(
        service_name="trading-system-engine",
        service_instance_name="trading-system-LH"
    )
    assert config.schema_name == "trading_system_lh"


def test_redis_namespace_derivation():
    """Test Redis namespace derivation."""
    # Singleton
    config = AdapterConfig(
        service_name="trading-system-engine",
        service_instance_name="trading-system-engine"
    )
    assert config.redis_namespace == "trading_system"

    # Multi-instance
    config = AdapterConfig(
        service_name="trading-system-engine",
        service_instance_name="trading-system-LH"
    )
    assert config.redis_namespace == "trading_system:LH"
```

### Integration Tests

**Test Coverage:**
1. Service registration with instance name in Redis
2. PostgreSQL queries use correct schema prefix
3. Redis operations use correct namespace prefix
4. Health endpoint returns instance name
5. Volume persistence across container restarts
6. Multi-instance schema isolation

**Example Integration Test (Go)**:
```go
func TestServiceRegistrationWithInstanceName(t *testing.T) {
    // Given: audit-correlator with SERVICE_INSTANCE_NAME=audit-correlator
    os.Setenv("SERVICE_INSTANCE_NAME", "audit-correlator")

    // When: Service registers
    cfg := config.Load()
    sd := infrastructure.NewServiceDiscovery(cfg, logger)
    err := sd.RegisterService(ctx)
    require.NoError(t, err)

    // Then: Redis key uses instance name (no :info suffix)
    key := "services:audit-correlator:audit-correlator"
    exists := redisClient.Exists(ctx, key).Val()
    assert.Equal(t, int64(1), exists)

    // Verify metadata includes instance information
    data := redisClient.Get(ctx, key).Val()
    var service models.ServiceRegistration
    json.Unmarshal([]byte(data), &service)
    assert.Equal(t, "audit-correlator", service.Metadata["instance_name"])
}

func TestMultiInstanceSchemaIsolation(t *testing.T) {
    // Instance 1: exchange-OKX
    os.Setenv("SERVICE_NAME", "exchange-simulator")
    os.Setenv("SERVICE_INSTANCE_NAME", "exchange-OKX")

    cfg1 := config.LoadRepositoryConfig()
    assert.Equal(t, "exchange_okx", cfg1.SchemaName)
    assert.Equal(t, "exchange:OKX", cfg1.RedisNamespace)

    adapter1, err := adapters.NewAuditDataAdapter(cfg1, logger)
    require.NoError(t, err)
    require.NoError(t, adapter1.Connect(ctx))

    // Create event in instance 1
    event1 := &models.AuditEvent{
        EventID:     "test-okx-001",
        ServiceName: "exchange-simulator",
        EventType:   "order_placed",
    }
    require.NoError(t, adapter1.Create(ctx, event1))

    // Instance 2: exchange-Binance
    os.Setenv("SERVICE_INSTANCE_NAME", "exchange-Binance")

    cfg2 := config.LoadRepositoryConfig()
    assert.Equal(t, "exchange_binance", cfg2.SchemaName)
    assert.Equal(t, "exchange:Binance", cfg2.RedisNamespace)

    adapter2, err := adapters.NewAuditDataAdapter(cfg2, logger)
    require.NoError(t, err)
    require.NoError(t, adapter2.Connect(ctx))

    // Verify instance 2 can't see instance 1's event
    event, err := adapter2.GetByID(ctx, "test-okx-001")
    assert.Error(t, err) // Should not find event from different schema
    assert.Nil(t, event)

    // Create event in instance 2
    event2 := &models.AuditEvent{
        EventID:     "test-binance-001",
        ServiceName: "exchange-simulator",
        EventType:   "order_placed",
    }
    require.NoError(t, adapter2.Create(ctx, event2))

    // Verify isolation: instance 1 can't see instance 2's event
    event, err = adapter1.GetByID(ctx, "test-binance-001")
    assert.Error(t, err)
    assert.Nil(t, event)
}
```

### Manual Testing Checklist

**Audit Correlator:**
- [ ] Run volume initialization: `cd orchestrator-docker && ./scripts/init-volumes.sh`
- [ ] Start with `SERVICE_INSTANCE_NAME=audit-correlator`
- [ ] Verify Redis key: `redis-cli KEYS "services:audit-correlator:*"`
- [ ] Verify PostgreSQL schema: `psql -U postgres -d trading_ecosystem -c "SELECT * FROM audit.health_check();"`
- [ ] Verify health endpoint: `curl http://localhost:8083/api/v1/health | jq .instance`
- [ ] Verify logs in `volumes/audit-correlator/logs/`
- [ ] Verify data in `volumes/audit-correlator/data/`
- [ ] Restart container: `docker restart trading-ecosystem-audit-correlator`
- [ ] Verify data persists after restart
- [ ] Check structured logs include instance_name field

**Grafana:**
- [ ] Access Grafana: http://localhost:3000 (admin/admin)
- [ ] Navigate to Trading Ecosystem folder
- [ ] Open DevOps Docker View dashboard
- [ ] Verify audit-correlator panel shows green health
- [ ] Open Simulation Entity View dashboard
- [ ] Verify audit-correlator appears as central service
- [ ] Check all panels render correctly

---

## Rollback Procedure

### Immediate Rollback (< 5 minutes)

If critical issues arise after deployment:

```bash
# Step 1: Stop services
cd orchestrator-docker
docker-compose down

# Step 2: Remove SERVICE_INSTANCE_NAME from environment
# Edit docker-compose.yml and remove SERVICE_INSTANCE_NAME lines
# Services will default to SERVICE_NAME (backward compatible)

# Step 3: Restart services
docker-compose up -d --force-recreate

# Step 4: Verify health
curl http://localhost:8083/api/v1/health
```

### PostgreSQL Schema Rollback (if needed)

If audit_events was moved to audit schema and needs to be reverted:

```sql
-- Connect to PostgreSQL
psql -U postgres -d trading_ecosystem

-- Move table back to public schema
ALTER TABLE audit.audit_events SET SCHEMA public;
ALTER SEQUENCE audit.audit_events_id_seq SET SCHEMA public;

-- Drop audit schema if empty
DROP SCHEMA IF EXISTS audit CASCADE;

-- Verify
\dt public.audit_events
```

### Redis Cleanup (if needed)

```bash
# Clear service discovery keys with new pattern
redis-cli KEYS "services:*" | xargs redis-cli DEL

# Services will re-register on next heartbeat with old pattern
```

### Volume Cleanup (if needed)

```bash
# Remove volume directories
cd orchestrator-docker
rm -rf volumes/audit-correlator

# Recreate if needed
mkdir -p volumes/audit-correlator/{data,logs}
chmod 777 volumes/audit-correlator/{data,logs}
```

### Verification After Rollback

```bash
# 1. Check service health
curl http://localhost:8083/api/v1/health

# 2. Verify service registration in Redis
redis-cli KEYS "services:*"

# 3. Check PostgreSQL tables
psql -U postgres -d trading_ecosystem -c "\dt public.*"

# 4. Verify logs show correct behavior
docker logs trading-ecosystem-audit-correlator
```

---

## Migration Path

### Backward Compatibility

**Guarantees:**
1. ✅ If `SERVICE_INSTANCE_NAME` not set → defaults to `SERVICE_NAME`
2. ✅ Existing deployments continue to work unchanged
3. ✅ Schema "audit" can be reused from existing deployment
4. ✅ Redis keys maintain existing patterns for singletons
5. ✅ No breaking changes to APIs or data models
6. ✅ All existing tests pass without modification

**Migration Steps:**
1. Deploy updated audit-data-adapter-go with Phase 0 changes
2. Deploy updated audit-correlator with `SERVICE_INSTANCE_NAME=audit-correlator`
3. Run PostgreSQL init script (handles existing table migration automatically)
4. Service discovery keys update automatically on next registration
5. Grafana dashboards deployed alongside (non-breaking)

### Rollout Order

**Phase 1: Singleton Services (Pilot - This Epic)**
1. ✅ **audit-correlator** (Go service, this plan)
2. **test-coordinator** (Python service, use Phase 9 pattern)

**Phase 2: First Multi-Instance Service (Validation)**
3. **exchange-simulator** (Go service)
   - Deploy `exchange-OKX` instance
   - Create `exchange_okx` schema
   - Test multi-instance pattern end-to-end

**Phase 3: Additional Multi-Instance Services**
4. **custodian-simulator** → `custodian-Komainu`
5. **market-data-simulator** → `market-data-Coinmetrics`

**Phase 4: Python Services**
6. **trading-system-engine-py** → `trading-system-LH`
7. **risk-monitor-py** → `risk-monitor-LH`

**Phase 5: Additional Instances (Future)**
8. `exchange-Binance`, `exchange-Coinbase`, etc.
9. Multiple trading-system instances per client
10. Multiple risk-monitor instances per client

---

## Deliverables

### Code Changes (Go Services)
- [ ] `audit-data-adapter-go/internal/config/config.go` - Add ServiceName, ServiceInstanceName, SchemaName, RedisNamespace (Phase 0) ⭐ CRITICAL
- [ ] `audit-correlator-go/internal/config/config.go` - Add ServiceInstanceName
- [ ] `audit-correlator-go/internal/infrastructure/service_discovery.go` - Update registration with instance name
- [ ] `audit-data-adapter-go/internal/postgres/*.go` - Update queries with schema prefix
- [ ] `audit-data-adapter-go/internal/redis/*.go` - Update keys with namespace prefix
- [ ] `audit-correlator-go/internal/handlers/health.go` - Add config field and update Health()
- [ ] `audit-correlator-go/cmd/server/main.go` - Update health handler constructor, add structured logging

### Code Changes (Python Services - Phase 9)
- [ ] `{service}/src/{service}/infrastructure/config.py` - Add instance support with schema/namespace properties
- [ ] `{service}-data-adapter-py/src/{service}_data_adapter/config.py` - Add AdapterConfig with derivation
- [ ] `{service}/src/{service}/main.py` - Integrate adapter with structured logging
- [ ] `{service}/src/{service}/presentation/health.py` - Add instance to health response

### Infrastructure Changes
- [ ] `orchestrator-docker/docker-compose.yml` - Add SERVICE_INSTANCE_NAME and volumes
- [ ] `orchestrator-docker/scripts/init-volumes.sh` - Volume initialization script ⭐ NEW
- [ ] `orchestrator-docker/postgres/init/02-audit-correlator-schema.sql` - Schema creation with migration
- [ ] `orchestrator-docker/grafana/dashboards/devops-docker-view.json` - DevOps dashboard with JSON
- [ ] `orchestrator-docker/grafana/dashboards/simulation-entity-view.json` - Simulation dashboard with JSON
- [ ] `orchestrator-docker/grafana/provisioning/dashboards/dashboards.yml` - Dashboard provisioning

### Documentation
- [x] This implementation plan (TSE-0001.12.0-IMPLEMENTATION-PLAN.md)
- [ ] Pull request documentation for audit-correlator changes
- [ ] Grafana dashboard usage guide
- [ ] Multi-instance deployment guide
- [ ] Python service implementation guide (included in Phase 9)

### Testing
- [ ] Unit tests for config parsing and derivation functions (Go)
- [ ] Unit tests for schema/namespace derivation (Python)
- [ ] Integration test for multi-instance schema isolation
- [ ] Integration tests for service registration and data access
- [ ] Manual testing checklist completion
- [ ] Grafana dashboard validation

---

## Success Criteria

1. ✅ audit-data-adapter-go loads SERVICE_INSTANCE_NAME and derives schema/namespace
2. ✅ audit-correlator starts with `SERVICE_INSTANCE_NAME=audit-correlator`
3. ✅ Service registers in Redis as `services:audit-correlator:audit-correlator`
4. ✅ PostgreSQL queries use `audit` schema with proper validation
5. ✅ Redis keys use `audit:*` namespace with proper validation
6. ✅ Health endpoint returns `"instance": "audit-correlator"`
7. ✅ Structured logs include instance_name field
8. ✅ Grafana DevOps dashboard shows audit-correlator with green health
9. ✅ Grafana Simulation dashboard shows audit-correlator as central service
10. ✅ Data persists in volumes across container restarts
11. ✅ Logs appear in `volumes/audit-correlator/logs/`
12. ✅ All existing tests pass without modification
13. ✅ Multi-instance integration test demonstrates schema isolation

---

## Dependencies

### Prerequisites
- Epic TSE-0001.4 complete (Data Adapters and Orchestrator Integration) ✅
- PostgreSQL 17 with schema support ✅
- Redis 8 with ACL support ✅
- Grafana 10.2.2+ ✅
- Docker Compose ✅

### Related Work
- Epic TSE-0001.3: gRPC Integration (provides health endpoints) ✅
- Epic TSE-0001.4: Data Adapters (provides PostgreSQL/Redis integration) ✅
- Epic TSE-0001.13: Grafana Metrics Integration with Prometheus (future)

---

## Risks and Mitigation

### Risk 1: Schema Migration Complexity
**Risk**: Multiple schemas complicate migrations
**Mitigation**:
- Migration tool applies to all schemas automatically
- Each schema has independent version tracking
- Singleton services reuse existing schemas (no migration needed)
- Automated migration script in Phase 6 handles existing data

### Risk 2: Redis Key Conflicts
**Risk**: Namespace collisions between instances
**Mitigation**:
- Clear naming pattern: `{service-type}:{instance-id}:{key}`
- Pattern validation in config loading
- Integration tests verify no collisions
- Namespace validation on adapter connection

### Risk 3: Grafana Dashboard Maintenance
**Risk**: Manual dashboard updates for each new instance
**Mitigation**:
- Start with manual dashboards (simpler, more reliable)
- JSON templates provided for easy customization
- Consider auto-discovery in future Epic TSE-0001.13
- Template dashboards for common patterns

### Risk 4: Volume Permission Issues
**Risk**: Container can't write to volumes
**Mitigation**:
- Provided `init-volumes.sh` script sets permissions correctly
- Document volume setup in deployment guide
- Add volume validation in health checks
- Clear error messages if volumes not accessible

### Risk 5: Configuration Derivation Errors
**Risk**: Schema/namespace derivation produces incorrect values
**Mitigation**:
- Comprehensive unit tests for derivation functions
- Configuration logging shows derived values at startup
- Validation functions check schema/namespace before use
- Integration tests verify correct behavior

---

## Future Enhancements

### Epic TSE-0001.13: Advanced Grafana Features
- Auto-discovery of new service instances via Prometheus service discovery
- Template dashboards with variables for instance selection
- Alert rules per instance with instance-specific thresholds
- SLA dashboards per entity with percentile metrics

### Epic TSE-0001.14: Multi-Instance Orchestration
- Automated instance creation via API
- Instance lifecycle management (start, stop, restart, scale)
- Configuration templates per entity type
- Health-based auto-scaling with Kubernetes integration

### Epic TSE-0001.15: Advanced Multi-Tenancy
- Cross-schema queries for correlation analysis
- Global audit trail across all instances
- Instance-level backups and restores with point-in-time recovery
- Data archival per instance with retention policies

---

## Timeline

**Total Duration**: 4-6 days for pilot (audit-correlator)

### Day 1: Foundation and Configuration
- Morning: **Phase 0** (audit-data-adapter-go config - CRITICAL)
- Afternoon: **Phase 1** (audit-correlator-go config layer)
- Testing: Unit tests for derivation functions

### Day 2: Service Discovery and Data Layer
- Morning: **Phase 2** (Service discovery integration)
- Afternoon: **Phase 3** (PostgreSQL schema support with validation)
- Testing: Integration tests for service registration

### Day 3: Redis and Deployment
- Morning: **Phase 4** (Redis namespace support with validation)
- Afternoon: **Phase 5** (Docker deployment and volume setup)
- Testing: Manual deployment testing

### Day 4: Infrastructure and Health
- Morning: **Phase 6** (PostgreSQL init scripts with migration)
- Afternoon: **Phase 7** (Health check enhancement)
- Testing: Schema migration and health endpoint testing

### Day 5: Observability
- Morning: **Phase 8** (Grafana dashboards with JSON)
- Afternoon: Dashboard testing and refinement
- Testing: Dashboard validation and metrics verification

### Day 6: Documentation and Validation
- Morning: **Phase 9** (Python service pattern documentation)
- Afternoon: Pull request documentation, deployment guide
- Testing: End-to-end validation, rollback procedure testing

---

## Conclusion

Epic TSE-0001.12.0 establishes the comprehensive foundation for named service instances with monitoring, observability, and multi-tenancy support. The pilot implementation in audit-correlator validates the complete pattern (Go + Python) before rolling out to multi-instance services.

**Critical Success Factor**: **Phase 0** (audit-data-adapter-go configuration) is mandatory and must be completed first. Without it, all subsequent phases will fail at runtime.

**Next Steps:**
1. Review and approve this updated implementation plan
2. Create feature branch: `feature/TSE-0001.12.0-named-components-foundation`
3. **Begin Phase 0**: audit-data-adapter-go configuration (CRITICAL)
4. Proceed through Phase 1-8 sequentially with testing at each step
5. Document Python pattern in Phase 9
6. Create comprehensive PR documentation
7. Merge pilot and roll out to remaining services

---

**Change Log:**
- 2025-10-06: Initial plan created
- 2025-10-06: Applied all critical fixes and improvements:
  - ⭐ Added Phase 0 (audit-data-adapter-go config - CRITICAL)
  - ⭐ Fixed service discovery key pattern (removed :info suffix)
  - ⭐ Fixed health handler config access (constructor injection)
  - ⭐ Added PostgreSQL schema migration logic
  - ⭐ Added structured logging with instance context
  - ⭐ Added error handling and validation strategies
  - ⭐ Added Phase 9 (Python service implementation pattern)
  - ⭐ Provided Grafana dashboard JSON templates
  - ⭐ Added volume initialization script
  - ⭐ Added multi-instance integration tests
  - ⭐ Added comprehensive rollback procedure

---

🤖 Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude <noreply@anthropic.com>
